{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch process Equivalent Widths with MCMC\n",
    "\n",
    "The goal of this notebook is to distill our analysis into a programmatic loop over many spectra and save the Equivalent Width (EW) and its uncertainty to a results table.  The table will be in the form of a pandas dataframe, which we'll then save as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldilocks_files = glob.glob('../data/HPF/Helium-transit-data/**/Goldilocks*.fits', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goldilocks_dataframe(fn):\n",
    "    \"\"\"Return a pandas Dataframe given a Goldilocks FITS file name\"\"\"\n",
    "    hdus = fits.open(fn)\n",
    "    df_original = pd.DataFrame()\n",
    "    for j in range(28):\n",
    "        df = pd.DataFrame()\n",
    "        for i in range(1, 10):\n",
    "            name = hdus[i].name\n",
    "            df[name] = hdus[i].data[j, :]\n",
    "        df['order'] = j\n",
    "        df_original = df_original.append(df, ignore_index=True)\n",
    "    keep_mask = df_original[df_original.columns[0:6]] != 0.0\n",
    "    df_original = df_original[keep_mask.all(axis=1)].reset_index(drop=True)\n",
    "    \n",
    "    return df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spectrum(df):\n",
    "    \"\"\"Normalizes spectrum to set to one\"\"\"\n",
    "    for order in df.order.unique():\n",
    "        mask = df.order == order\n",
    "        norm_constant = df['Sci Flux'][mask].median() #mean takes outliers into account\n",
    "        df['Sci Flux'][mask] = df['Sci Flux'][mask]/norm_constant\n",
    "        df['Sci Error'][mask] = df['Sci Error'][mask]/norm_constant\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_model(m, b, A, mu, logw, int_wl = 10330, wl = None):\n",
    "    \"\"\"Generate the model given parameters\"\"\"\n",
    "    continuum = m * (wl - int_wl) + b\n",
    "    w = np.exp(logw)\n",
    "    gaussian = A * np.exp(-0.5*(wl-mu)**2/w**2)\n",
    "    return continuum - gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, wl = None, flux = None, unc = None):\n",
    "    m, b, A, mu, logw = theta\n",
    "    model = generative_model(m, b, A, mu, logw, int_wl = 10345, wl = wl)\n",
    "    residual = flux - model\n",
    "    chi_squared = np.sum(residual** 2 / unc**2)\n",
    "    return -0.5 * chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we will loop over index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 16\n",
    "n_walkers = 32\n",
    "n_params = 5\n",
    "n_steps = 5000\n",
    "labels = [\"m\", \"b\", \"A\", \"mu\", \"w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 Goldilocks_20200807T091125_v1.0_0037.spectra.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:11<00:00, 421.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09290395652081108\n",
      "0.008553367320034684\n",
      "130 Goldilocks_20200807T092540_v1.0_0038.spectra.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:12<00:00, 415.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1096880131914182\n",
      "0.007026452154011127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index in range(129, 131):\n",
    "\n",
    "    fn = goldilocks_files[index]\n",
    "    print(index, fn[-49:])\n",
    "    df = normalize_spectrum(get_goldilocks_dataframe(fn))\n",
    "    \n",
    "    \n",
    "    sub_region = (df.order == order) & (df['Sci Wavl'] > 10343.5) & (df['Sci Wavl'] < 10348.5)\n",
    "    wl = df['Sci Wavl'][sub_region].values\n",
    "    flux = df['Sci Flux'][sub_region].values\n",
    "    unc = df['Sci Error'][sub_region].values\n",
    "\n",
    "    m_guess, b_guess, A_guess, mu_guess, logw_guess = 0.01, 1, 0.1, 10345, np.log(0.4)\n",
    "    theta_guess = np.array([m_guess, b_guess, A_guess, mu_guess, logw_guess])\n",
    "    \n",
    "    pos = theta_guess + 1e-4 * np.random.randn(n_walkers, n_params) #intial guess position\n",
    "    \n",
    "    kwargs = {'wl':wl, 'flux':flux, 'unc':unc} #dictionary to use these values when function called\n",
    "    sampler = emcee.EnsembleSampler(n_walkers, n_params, log_likelihood, kwargs = kwargs)\n",
    "    sampler.run_mcmc(pos, n_steps, progress=True);\n",
    "    \n",
    "    flat_samples = sampler.get_chain(discard=1000, thin=15, flat=True) #remove first 1000 and take every 15th\n",
    "\n",
    "    A_draws = flat_samples[:,2]\n",
    "    b_draws = flat_samples[:,1]\n",
    "    m_draws = flat_samples[:,0]\n",
    "    mu_draws = flat_samples[:,3]\n",
    "    w_draws = np.exp(flat_samples[:, 4])\n",
    "\n",
    "    EW = ((2*np.pi)**.5)*(A_draws*w_draws)/(m_draws*(mu_draws-10345)+b_draws)\n",
    "    EW\n",
    "\n",
    "    ew_mean = np.mean(EW)\n",
    "    ew_std = np.std(EW)\n",
    "    print(ew_mean)\n",
    "    print(ew_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
