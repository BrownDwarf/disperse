{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch process Equivalent Widths with MCMC\n",
    "\n",
    "The goal of this notebook is to distill our analysis into a programmatic loop over many spectra and save the Equivalent Width (EW) and its uncertainty to a results table.  The table will be in the form of a pandas dataframe, which we'll then save as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldilocks_files = glob.glob('../data/HPF/Helium-transit-data/**/Goldilocks*.fits', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_zero = goldilocks_files[0]\n",
    "hdus = fits.open(filename_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goldilocks_dataframe(fn):\n",
    "    \"\"\"Return a pandas Dataframe given a Goldilocks FITS file name\"\"\"\n",
    "    hdus = fits.open(fn)\n",
    "    df_original = pd.DataFrame()\n",
    "    header = hdus[0].header\n",
    "    for j in range(28):\n",
    "        df = pd.DataFrame()\n",
    "        for i in range(1, 10):\n",
    "            name = hdus[i].name\n",
    "            df[name] = hdus[i].data[j, :]\n",
    "        df['order'] = j\n",
    "        df_original = df_original.append(df, ignore_index=True)\n",
    "    keep_mask = df_original[df_original.columns[0:6]] != 0.0\n",
    "    df_original = df_original[keep_mask.all(axis=1)].reset_index(drop=True)\n",
    "    \n",
    "    return df_original, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spectrum(df):\n",
    "    \"\"\"Normalizes spectrum to set to one\"\"\"\n",
    "    for order in df.order.unique():\n",
    "        mask = df.order == order\n",
    "        norm_constant = df['Sci Flux'][mask].median() #mean takes outliers into account\n",
    "        df['Sci Flux'][mask] = df['Sci Flux'][mask]/norm_constant\n",
    "        df['Sci Error'][mask] = df['Sci Error'][mask]/norm_constant\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we will loop over index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 4\n",
    "n_walkers = 32\n",
    "n_params = 5\n",
    "n_steps = 5000\n",
    "labels = [\"m\", \"b\", \"A\", \"mu\", \"w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 Goldilocks_20200919T063924_v1.0_0024.spectra.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:37<00:00, 133.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.066814412157174\n",
      "0.021731192110355336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index in range(125, 126):\n",
    "\n",
    "    fn = goldilocks_files[index]\n",
    "    print(index, fn[-49:])\n",
    "    df_orig, header = get_goldilocks_dataframe(fn)\n",
    "    date_raw = hdus[0].header['DATE-OBS']\n",
    "    date = date_raw[0:10]\n",
    "    time = date_raw[11:19]\n",
    "    obj = hdus[0].header['OBJECT']\n",
    "    df = normalize_spectrum(df_orig)    \n",
    "    \n",
    "    wavelength1 = 8538\n",
    "    wavelength2 = 8546\n",
    "    calcium_line = 8542\n",
    "    \n",
    "    sub_region = (df.order == order) & (df['Sci Wavl'] > wavelength1) & (df['Sci Wavl'] < wavelength2)\n",
    "    wl = df['Sci Wavl'][sub_region].values\n",
    "    flux = df['Sci Flux'][sub_region].values\n",
    "    unc = df['Sci Error'][sub_region].values\n",
    "    \n",
    "    def generative_model(m, b, A, mu, logw, int_wl = calcium_line):\n",
    "        \"\"\"Generate the model given parameters\"\"\"\n",
    "        continuum = m * (wl - int_wl) + b\n",
    "        w = np.exp(logw)\n",
    "        gaussian = A * np.exp(-0.5*(wl-mu)**2/w**2)\n",
    "        return continuum - gaussian\n",
    "    \n",
    "    def log_likelihood(theta):\n",
    "        m, b, A, mu, logw = theta\n",
    "        model = generative_model(m, b, A, mu, logw, int_wl = calcium_line)\n",
    "        residual = flux - model\n",
    "        chi_squared = np.sum(residual** 2 / unc**2)\n",
    "        return -0.5 * chi_squared\n",
    "    \n",
    "    m_guess, b_guess, A_guess, mu_guess, logw_guess = 0.01, 0.3, 0.1, calcium_line, np.log(0.4)\n",
    "    theta_guess = np.array([m_guess, b_guess, A_guess, mu_guess, logw_guess])\n",
    "    \n",
    "    pos = theta_guess + 1e-4 * np.random.randn(n_walkers, n_params) #intial guess position\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(n_walkers, n_params, log_likelihood)\n",
    "    sampler.run_mcmc(pos, n_steps, progress=True);\n",
    "    \n",
    "    flat_samples = sampler.get_chain(discard=1000, thin=15, flat=True)\n",
    "\n",
    "    A_draws = flat_samples[:,2]\n",
    "    b_draws = flat_samples[:,1]\n",
    "    m_draws = flat_samples[:,0]\n",
    "    mu_draws = flat_samples[:,3]\n",
    "    w_draws = np.exp(flat_samples[:, 4])\n",
    "\n",
    "    EW = ((2*np.pi)**.5)*(A_draws*w_draws)/(m_draws*(mu_draws-calcium_line)+b_draws)\n",
    "    EW\n",
    "\n",
    "    ew_mean = np.mean(EW)\n",
    "    ew_std = np.std(EW)\n",
    "    print(ew_mean)\n",
    "    print(ew_std)\n",
    "    temp = {'ew':ew_mean, 'ew_unc':ew_std, 'date':date, 'star_name':obj, 'time':time, 'int_wv':calcium_line}\n",
    "    df_results = df_results.append(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ew</th>\n",
       "      <th>ew_unc</th>\n",
       "      <th>star_name</th>\n",
       "      <th>time</th>\n",
       "      <th>int_wv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>-0.032368</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>HAT-P-11</td>\n",
       "      <td>09:48:47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>1.067472</td>\n",
       "      <td>0.021095</td>\n",
       "      <td>HAT-P-11</td>\n",
       "      <td>09:48:47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>1.066814</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>HAT-P-11</td>\n",
       "      <td>09:48:47</td>\n",
       "      <td>8542.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        ew    ew_unc star_name      time  int_wv\n",
       "0  2020-07-16 -0.032368  0.001764  HAT-P-11  09:48:47     NaN\n",
       "1  2020-07-16  1.067472  0.021095  HAT-P-11  09:48:47     NaN\n",
       "2  2020-07-16  1.066814  0.021731  HAT-P-11  09:48:47  8542.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It works!  Let's save the results to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('../data/preliminary_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
